{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9e1c66",
   "metadata": {},
   "source": [
    "## Tweet Emotion Classification with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccda16e",
   "metadata": {},
   "source": [
    "### Project Overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9405aa57",
   "metadata": {},
   "source": [
    "This project is all about classifying emotions in tweets using Scikit-learn. I used TF-IDF to convert the tweets into numerical features the model could understand, then tested out a logistic regression approach with a few tuning tricks to boost accuracy. The goal was to try different modeling techniques and explore how different preprocessing and modeling choices could impact performance on real-world text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f5e332",
   "metadata": {},
   "source": [
    "### Project Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33cefb1",
   "metadata": {},
   "source": [
    "My goal with this project was to get hands-on with natural language processing and practice building a model that could recognize emotions in text. Along the way, I experimented with preprocessing steps and model parameters to see what worked best. More than just optimizing for high accuracy, I wanted this to be a meaningful learning experience and something others could reference when working on similar text classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ba69da",
   "metadata": {},
   "source": [
    "## Project Walkthrough:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bde0bd",
   "metadata": {},
   "source": [
    "### 1. Importing Libraries and Loading Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b952e494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel awful about it too because it s my job ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im alone i feel awful</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ive probably mentioned this before but i reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i was feeling a little low few days back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i beleive that i am much more sensitive to oth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i feel awful about it too because it s my job ...      0\n",
       "1                              im alone i feel awful      0\n",
       "2  ive probably mentioned this before but i reall...      1\n",
       "3           i was feeling a little low few days back      0\n",
       "4  i beleive that i am much more sensitive to oth...      2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Loading Twitter dataset:\n",
    "data = pd.read_parquet('train-00000-of-00001.parquet')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c6f8c",
   "metadata": {},
   "source": [
    "***Explanation:***\n",
    "\n",
    "The Twitter dataset is stored in **Parquet** format, which efficiently handles large datasets. I loaded it using Pandas and took a quick look at the first few rows to better understand the overall structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529e44a",
   "metadata": {},
   "source": [
    "### 2. Exploring Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c828e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 416809 entries, 0 to 416808\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    416809 non-null  object\n",
      " 1   label   416809 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Checking the structure of the data more deeply\n",
    "print(data.info()) #to understand the columns, data types, and non-null counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38275b0b-cb82-4533-8d9b-834390e5f887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "1    141067\n",
      "0    121187\n",
      "3     57317\n",
      "4     47712\n",
      "2     34554\n",
      "5     14972\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking the distribution of the target labels (in this case, emotions)\n",
    "print(data['label'].value_counts()) # we use 'value_counts' on the 'label' column -\n",
    "                                    #to see how many instances of each emotion are present."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2bfb37",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing and Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd3e73a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  emotion\n",
      "0  i feel awful about it too because it s my job ...  sadness\n",
      "1                              im alone i feel awful  sadness\n",
      "2  ive probably mentioned this before but i reall...      joy\n",
      "3           i was feeling a little low few days back  sadness\n",
      "4  i beleive that i am much more sensitive to oth...     love\n"
     ]
    }
   ],
   "source": [
    "# Mapping labels to emotion names for readability (this step is optional, but I prefer to do it this way)\n",
    "emotion_map = {0: 'sadness', 1: 'joy', 2: 'love', 3: 'anger', 4: 'fear', 5: 'surprise'}\n",
    "data['emotion'] = data['label'].map(emotion_map)\n",
    "\n",
    "# Previewing the updated DataFrame:\n",
    "print(data[['text', 'emotion']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c8a78",
   "metadata": {},
   "source": [
    "***Explanation:***\n",
    "\n",
    "Here, I'm mappping the numeric labels to names that are readable and easy to understand for us (humans). Doing so can improve interpretability in the overall analysis and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93afa397",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering with TF-IDF:\n",
    "\n",
    "***Here, the goal is to transform raw data into relevant information our machine learning model can use. In other words, I'm setting up the parameters required to be able to train our machine learning model.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4005ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining features and target:\n",
    "X = data['text']  # text data\n",
    "y = data['label']  #numeric labels\n",
    "\n",
    "# Splitting data into training and testing sets:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converting text to numerical data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6480c1e",
   "metadata": {},
   "source": [
    "***Explanation:***\n",
    "\n",
    "***TF-IDF Vectorizer:*** Converts text data into a numerical format that models can process. When we set max_features=5000, we limit the vocabulary size, balancing model accuracy and computational efficiency.\n",
    "\n",
    "***Data Splitting:*** Here I'm using an 80/20 train-test split to evaluate model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c18d99",
   "metadata": {},
   "source": [
    "### 5. Model Training and Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e63eef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.84      0.95      0.89     24504\n",
      "         joy       0.78      0.97      0.87     28247\n",
      "        love       0.96      0.43      0.59      6853\n",
      "       anger       0.94      0.77      0.84     11339\n",
      "        fear       0.90      0.69      0.78      9376\n",
      "    surprise       0.98      0.24      0.38      3043\n",
      "\n",
      "    accuracy                           0.84     83362\n",
      "   macro avg       0.90      0.68      0.73     83362\n",
      "weighted avg       0.85      0.84      0.82     83362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training a Multinomial Naive Bayes classifier\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# To make predictions on the test data\n",
    "y_pred = model.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluating the model's accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=emotion_map.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd2eff0",
   "metadata": {},
   "source": [
    "***Explanation:***\n",
    "\n",
    "***Model Choice:*** Naive Bayes \n",
    "\n",
    "Naive Bayes works fast and effectively, especially with high dimensional datasets like text (in this case). Overall, this model type is considered a popular choice for text classification. \n",
    "\n",
    "***Evaluation:*** At the evaluation step, we need to calculate for accuracy and provide a detailed classification report, which shows metrics such as precision, recall, and F1-score for each emotion. High F1-scores mean that we have a good balance between precision and recall. On the other hand, low F1-scores suggest that the model is having trouble balancing precision and recall. \n",
    "\n",
    "***Output Interpretation:*** \n",
    "\n",
    "\n",
    "Overall, we can see that the model achieves a total accuracy of ***84%***. This accuracy percentage suggests that the model's performance is reliable for emotion classification. I noticed that it performs particularly well with joy and sadness, showing high recall and balanced F1-scores, sugesting that it's identifying these emotions accurately and effectively. \n",
    "\n",
    "When it comes to love, anger, and fear, the model shows high precision but lower recall, which means that it recognizes these emotions correctly when predicted, but misses many occurences. The surprise category shows very high precision but very low recall, indicating that the model rarely predicts surprise, but when it does it is usually correct.\n",
    "\n",
    "\n",
    "The macro and weighted averages show that our model's performance varies across emotions (predicting some emotions more accurately than others). This indicates that there is room for improvement and that our original model may benefit from some improvements so that it can better recall other emotions like surprise and love."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9afa1",
   "metadata": {},
   "source": [
    "### 6. Additional Enhancements and Model Comparison:\n",
    "\n",
    "***Adding Logistic Regression Model for Comparison with Naive Bayes Model***\n",
    "\n",
    "So far, we have a working model. However, one of my main goals with this project was to maximize accuracy  and make it useful. So I decided to add another model training and evaluation section using a different model type. I will be using a Logistic Regression model, which is a common alternative for text classification, and I will compare its performace with Naive Bayes to see which one performs better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "099ebc60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (with scaling and solver='saga'): 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     sadness       0.94      0.94      0.94     24504\n",
      "         joy       0.92      0.93      0.92     28247\n",
      "        love       0.80      0.77      0.78      6853\n",
      "       anger       0.89      0.90      0.90     11339\n",
      "        fear       0.85      0.84      0.85      9376\n",
      "    surprise       0.78      0.71      0.74      3043\n",
      "\n",
      "    accuracy                           0.90     83362\n",
      "   macro avg       0.86      0.85      0.86     83362\n",
      "weighted avg       0.90      0.90      0.90     83362\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# Scaling the TF-IDF features\n",
    "scaler = MaxAbsScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_vectorized)\n",
    "X_test_scaled = scaler.transform(X_test_vectorized)\n",
    "\n",
    "# Initializing the Logistic Regression model with increased max_iter and an alternative solver\n",
    "lr_model = LogisticRegression(max_iter=500, solver='saga', random_state=42)\n",
    "\n",
    "# Training the model on the scaled training data\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# To make predictions on the scaled test data\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluating our new model's accuracy\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(f\"Logistic Regression Accuracy (with scaling and solver='saga'): {accuracy_lr:.2f}\")\n",
    "print(classification_report(y_test, y_pred_lr, target_names=emotion_map.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd516348",
   "metadata": {},
   "source": [
    "***Explanation:***\n",
    "\n",
    "***New Model Choice:*** Logistic Regression. \n",
    "\n",
    "\n",
    "When it comes to text classification, logistic Regression usually outperforms Naive Bayes because it doesn't assume that words are independent of each other. This model type is better for capturing complex relationships between words, which leads to more accurate predictions. Moreover, logistic regression gives us reliable probability estimates and supports techniques to prevent overfitting. Overall, this is a very robust choice for handling the intricacies of text data. \n",
    "\n",
    "***Output Interpretation:*** \n",
    "\n",
    "\n",
    "When setting up the new logistic regression model, I implemented data scaling and utilized the 'saga' solver, which has led to significant improvements in the model's performance for emotion classification of tweets. The overall accuracy of the model increased from ***84%*** to ***90%***. \n",
    "\n",
    "The class-wise analysis also shows big improvements, especially for the 'surprise' and 'love' emotions, with F1-scores improving from ***0.38*** to ***0.74*** and from ***0.59*** to ***0.78***, etc. Additionally, other emotions also had some small performance gains. \n",
    "\n",
    "Moreover, both macro and weighted averages of precision, recall, and F1-score got better, which indicates a more accurate and balanced classificationn across all categories of emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321bc10",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "\n",
    "This project began as an opportunity to deepen my understanding of Scikit-learn and apply it to a real-world NLP task. Along the way, I explored key text classification techniques, experimented with different models, and examined the impact of preprocessing choices on performance. By building on foundational knowledge in data science and insights from Kaggle resources, I created a scalable and interpretable workflow for multi-class emotion detection. I hope this project provides both practical insights and inspiration for anyone working with text data or looking to strengthen their machine learning skill set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357db7d3",
   "metadata": {},
   "source": [
    "## Dataset Info:\n",
    "\n",
    "***Source:*** \"Twitter Emotion Classification Dataset\" on Kaggle.com (labeled tweets for multi-class emotion detection)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e38b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
